{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1062b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7090b8",
   "metadata": {},
   "source": [
    "## gen_forg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defebec9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-66b47b960a55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "## TRAIN DATA - gen_forg\n",
    "\n",
    "rootdir = r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Train'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"x\", \"y\", \"pressure\", \"azimuth\", \"elevation\", \"id\"])\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        data = pd.read_csv(path, names = [\"data\"])\n",
    "        \n",
    "        new = data[\"data\"].str.split(\"   \", expand = True)\n",
    "\n",
    "        data[\"x\"] = new[1]\n",
    "        data[\"y\"] = new[2]\n",
    "        data[\"pressure\"] = new[3]\n",
    "        data[\"azimuth\"] = new[4]\n",
    "        data[\"elevation\"] = new[5]\n",
    "\n",
    "        data = data.drop([\"data\"], axis = 1)\n",
    "        \n",
    "        data[\"id\"] = path[-11:-4]\n",
    "        \n",
    "        df = pd.concat([df, data], ignore_index = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da4cbafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1226954, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf88556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\train_gen_forg.csv\")\n",
    "\n",
    "df1 = df[:700000]\n",
    "df2 = df[700000:]\n",
    "\n",
    "df1.to_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\tr1.csv', index = False)\n",
    "df2.to_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\tr2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ad19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500aea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\tr1.csv')\n",
    "df2 = pd.read_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\tr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097ac556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a76b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1226721, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c55baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\train_gen_forg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2073c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rootdir, df, path, data, new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fefb2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test DATA - gen_forg\n",
    "\n",
    "rootdir = r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Test'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"x\", \"y\", \"pressure\", \"azimuth\", \"elevation\", \"id\"])\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        data = pd.read_csv(path, names = [\"data\"])\n",
    "        \n",
    "        new = data[\"data\"].str.split(\"   \", expand = True)\n",
    "\n",
    "        data[\"x\"] = new[1]\n",
    "        data[\"y\"] = new[2]\n",
    "        data[\"pressure\"] = new[3]\n",
    "        data[\"azimuth\"] = new[4]\n",
    "        data[\"elevation\"] = new[5]\n",
    "\n",
    "        data = data.drop([\"data\"], axis = 1)\n",
    "        \n",
    "        data[\"id\"] = path[-11:-4]\n",
    "        \n",
    "        df = pd.concat([df, data], ignore_index = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85816ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971838, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e17a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pressure</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3290000e+03</td>\n",
       "      <td>8.3170000e+03</td>\n",
       "      <td>3.6900000e+02</td>\n",
       "      <td>6.6000000e+01</td>\n",
       "      <td>1.3700000e+02</td>\n",
       "      <td>0060f00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3290000e+03</td>\n",
       "      <td>8.3170000e+03</td>\n",
       "      <td>4.1300000e+02</td>\n",
       "      <td>6.5000000e+01</td>\n",
       "      <td>1.3700000e+02</td>\n",
       "      <td>0060f00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3290000e+03</td>\n",
       "      <td>8.3170000e+03</td>\n",
       "      <td>4.5600000e+02</td>\n",
       "      <td>6.4000000e+01</td>\n",
       "      <td>1.3800000e+02</td>\n",
       "      <td>0060f00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3160000e+03</td>\n",
       "      <td>8.2920000e+03</td>\n",
       "      <td>5.6100000e+02</td>\n",
       "      <td>6.3000000e+01</td>\n",
       "      <td>1.3700000e+02</td>\n",
       "      <td>0060f00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3160000e+03</td>\n",
       "      <td>8.2550000e+03</td>\n",
       "      <td>6.1700000e+02</td>\n",
       "      <td>6.3000000e+01</td>\n",
       "      <td>1.3500000e+02</td>\n",
       "      <td>0060f00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x              y       pressure        azimuth      elevation  \\\n",
       "0  1.3290000e+03  8.3170000e+03  3.6900000e+02  6.6000000e+01  1.3700000e+02   \n",
       "1  1.3290000e+03  8.3170000e+03  4.1300000e+02  6.5000000e+01  1.3700000e+02   \n",
       "2  1.3290000e+03  8.3170000e+03  4.5600000e+02  6.4000000e+01  1.3800000e+02   \n",
       "3  1.3160000e+03  8.2920000e+03  5.6100000e+02  6.3000000e+01  1.3700000e+02   \n",
       "4  1.3160000e+03  8.2550000e+03  6.1700000e+02  6.3000000e+01  1.3500000e+02   \n",
       "\n",
       "        id  \n",
       "0  0060f00  \n",
       "1  0060f00  \n",
       "2  0060f00  \n",
       "3  0060f00  \n",
       "4  0060f00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78b5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\test_gen_forg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f7aa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rootdir, df, path, data, new "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e395f",
   "metadata": {},
   "source": [
    "## genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e6d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN DATA - genuine\n",
    "\n",
    "rootdir = r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Train'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"x\", \"y\", \"pressure\", \"azimuth\", \"elevation\", \"id\"])\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        \n",
    "        if \"v\" in path[-11:-4]:\n",
    "            data = pd.read_csv(path, names = [\"data\"])\n",
    "        \n",
    "            new = data[\"data\"].str.split(\"   \", expand = True)\n",
    "\n",
    "            data[\"x\"] = new[1]\n",
    "            data[\"y\"] = new[2]\n",
    "            data[\"pressure\"] = new[3]\n",
    "            data[\"azimuth\"] = new[4]\n",
    "            data[\"elevation\"] = new[5]\n",
    "\n",
    "            data = data.drop([\"data\"], axis = 1)\n",
    "        \n",
    "            data[\"id\"] = path[-11:-4]\n",
    "        \n",
    "            df = pd.concat([df, data], ignore_index = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e480b626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497168, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdfff0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pressure</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.7440000e+03</td>\n",
       "      <td>8.0240000e+03</td>\n",
       "      <td>5.4000000e+01</td>\n",
       "      <td>5.8000000e+01</td>\n",
       "      <td>1.1500000e+02</td>\n",
       "      <td>0000v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.9110000e+03</td>\n",
       "      <td>8.2170000e+03</td>\n",
       "      <td>1.4600000e+02</td>\n",
       "      <td>5.8000000e+01</td>\n",
       "      <td>1.1600000e+02</td>\n",
       "      <td>0000v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.8960000e+03</td>\n",
       "      <td>8.2410000e+03</td>\n",
       "      <td>3.1400000e+02</td>\n",
       "      <td>5.8000000e+01</td>\n",
       "      <td>1.1600000e+02</td>\n",
       "      <td>0000v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.8960000e+03</td>\n",
       "      <td>8.2490000e+03</td>\n",
       "      <td>4.2200000e+02</td>\n",
       "      <td>5.8000000e+01</td>\n",
       "      <td>1.1600000e+02</td>\n",
       "      <td>0000v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.8960000e+03</td>\n",
       "      <td>8.2490000e+03</td>\n",
       "      <td>5.0400000e+02</td>\n",
       "      <td>5.9000000e+01</td>\n",
       "      <td>1.1700000e+02</td>\n",
       "      <td>0000v00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x              y       pressure        azimuth      elevation  \\\n",
       "0  1.7440000e+03  8.0240000e+03  5.4000000e+01  5.8000000e+01  1.1500000e+02   \n",
       "1  1.9110000e+03  8.2170000e+03  1.4600000e+02  5.8000000e+01  1.1600000e+02   \n",
       "2  1.8960000e+03  8.2410000e+03  3.1400000e+02  5.8000000e+01  1.1600000e+02   \n",
       "3  1.8960000e+03  8.2490000e+03  4.2200000e+02  5.8000000e+01  1.1600000e+02   \n",
       "4  1.8960000e+03  8.2490000e+03  5.0400000e+02  5.9000000e+01  1.1700000e+02   \n",
       "\n",
       "        id  \n",
       "0  0000v00  \n",
       "1  0000v00  \n",
       "2  0000v00  \n",
       "3  0000v00  \n",
       "4  0000v00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb7f8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\train_gen.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f13f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rootdir, df, path, data, new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20d18859",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST DATA - genuine\n",
    "\n",
    "rootdir = r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Test'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"x\", \"y\", \"pressure\", \"azimuth\", \"elevation\", \"id\"])\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        \n",
    "        if \"v\" in path[-11:-4]:\n",
    "            data = pd.read_csv(path, names = [\"data\"])\n",
    "        \n",
    "            new = data[\"data\"].str.split(\"   \", expand = True)\n",
    "\n",
    "            data[\"x\"] = new[1]\n",
    "            data[\"y\"] = new[2]\n",
    "            data[\"pressure\"] = new[3]\n",
    "            data[\"azimuth\"] = new[4]\n",
    "            data[\"elevation\"] = new[5]\n",
    "\n",
    "            data = data.drop([\"data\"], axis = 1)\n",
    "        \n",
    "            data[\"id\"] = path[-11:-4]\n",
    "        \n",
    "            df = pd.concat([df, data], ignore_index = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2fefbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379461, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d6e4af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pressure</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2350000e+03</td>\n",
       "      <td>8.1440000e+03</td>\n",
       "      <td>8.6000000e+01</td>\n",
       "      <td>6.7000000e+01</td>\n",
       "      <td>1.3500000e+02</td>\n",
       "      <td>0060v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2410000e+03</td>\n",
       "      <td>8.1800000e+03</td>\n",
       "      <td>1.9500000e+02</td>\n",
       "      <td>6.7000000e+01</td>\n",
       "      <td>1.3500000e+02</td>\n",
       "      <td>0060v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2410000e+03</td>\n",
       "      <td>8.1890000e+03</td>\n",
       "      <td>2.9600000e+02</td>\n",
       "      <td>6.7000000e+01</td>\n",
       "      <td>1.3500000e+02</td>\n",
       "      <td>0060v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2410000e+03</td>\n",
       "      <td>8.1970000e+03</td>\n",
       "      <td>3.8400000e+02</td>\n",
       "      <td>6.5000000e+01</td>\n",
       "      <td>1.3500000e+02</td>\n",
       "      <td>0060v00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2410000e+03</td>\n",
       "      <td>8.2040000e+03</td>\n",
       "      <td>4.5000000e+02</td>\n",
       "      <td>6.5000000e+01</td>\n",
       "      <td>1.3500000e+02</td>\n",
       "      <td>0060v00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x              y       pressure        azimuth      elevation  \\\n",
       "0  1.2350000e+03  8.1440000e+03  8.6000000e+01  6.7000000e+01  1.3500000e+02   \n",
       "1  1.2410000e+03  8.1800000e+03  1.9500000e+02  6.7000000e+01  1.3500000e+02   \n",
       "2  1.2410000e+03  8.1890000e+03  2.9600000e+02  6.7000000e+01  1.3500000e+02   \n",
       "3  1.2410000e+03  8.1970000e+03  3.8400000e+02  6.5000000e+01  1.3500000e+02   \n",
       "4  1.2410000e+03  8.2040000e+03  4.5000000e+02  6.5000000e+01  1.3500000e+02   \n",
       "\n",
       "        id  \n",
       "0  0060v00  \n",
       "1  0060v00  \n",
       "2  0060v00  \n",
       "3  0060v00  \n",
       "4  0060v00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7becad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\test_gen.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd84db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rootdir, df, path, data, new "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
