{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a49de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316581d2",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e403d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\test_gen.csv\")\n",
    "\n",
    "\n",
    "gen_forg = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\test_gen_forg.csv\")\n",
    "\n",
    "genuine = genuine.fillna(0)\n",
    "gen_forg = gen_forg.fillna(0)\n",
    "\n",
    "genuine = genuine.groupby('ID').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "gen_forg = gen_forg.groupby('ID').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "\n",
    "ids = []\n",
    "\n",
    "for i in gen_forg[\"ID\"]:\n",
    "    ids.append(i)\n",
    "    \n",
    "    \n",
    "new_id = []\n",
    "\n",
    "for i in ids:\n",
    "    new_i = i.replace(\"test\\\\\", \"\")\n",
    "    new_id.append(new_i)\n",
    "    \n",
    "gen_forg[\"ID\"] = new_id\n",
    "\n",
    "genuine['g_key'] = genuine['ID'].str[:4]\n",
    "gen_forg['fg_key'] = gen_forg['ID'].str[:4]\n",
    "\n",
    "dicti_g = {\n",
    "    'ID':\"G_ID\", 'X':\"G_X\", 'Y':\"G_Y\", 'PRESSURE':\"G_PRESSURE\", 'AZIMUTH':\"G_AZIMUTH\", 'ELEVATION':\"G_ELEVATION\", \n",
    "    'POSITION':\"G_POSITION\",\n",
    "        'DISPLACEMENT':\"G_DISPLACEMENT\", 'VELOCITY':\"G_VELOCITY\", 'ANGULAR_VELOCITY':\"G_ANGULAR_VELOCITY\", 'ACCELERATION':\"G_ACCELERATION\",\n",
    "        'CENTRIPETAL_ACCELERATION':\"G_CENTRIPETAL_ACCELERATION\", 'TANGENTIAL_ACCELERATION':\"G_TANGENTIAL_ACCELERATION\"\n",
    "}\n",
    "\n",
    "genuine.rename(columns = dicti_g, inplace = True)\n",
    "\n",
    "dicti_fg = {\n",
    "    'ID':\"FG_ID\", 'X':\"FG_X\", 'Y':\"FG_Y\", 'PRESSURE':\"FG_PRESSURE\", 'AZIMUTH':\"FG_AZIMUTH\", 'ELEVATION':\"FG_ELEVATION\", \n",
    "    'POSITION':\"FG_POSITION\",\n",
    "        'DISPLACEMENT':\"FG_DISPLACEMENT\", 'VELOCITY':\"FG_VELOCITY\", 'ANGULAR_VELOCITY':\"FG_ANGULAR_VELOCITY\", 'ACCELERATION':\"FG_ACCELERATION\",\n",
    "        'CENTRIPETAL_ACCELERATION':\"FG_CENTRIPETAL_ACCELERATION\", 'TANGENTIAL_ACCELERATION':\"FG_TANGENTIAL_ACCELERATION\"\n",
    "}\n",
    "\n",
    "gen_forg.rename(columns = dicti_fg, inplace = True)\n",
    "\n",
    "genuine.rename(columns = {\"g_key\": \"key\"}, inplace = True)\n",
    "gen_forg.rename(columns = {\"fg_key\": \"key\"}, inplace = True)\n",
    "\n",
    "result = pd.merge(genuine, gen_forg, on ='key').drop(\"key\", 1)\n",
    "\n",
    "result[\"FG_X\"] = result[\"FG_X\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_Y\"] = result[\"FG_Y\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_PRESSURE\"] = result[\"FG_PRESSURE\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_AZIMUTH\"] = result[\"FG_AZIMUTH\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_ELEVATION\"] = result[\"FG_ELEVATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_POSITION\"] = result[\"FG_POSITION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_DISPLACEMENT\"] = result[\"FG_DISPLACEMENT\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_VELOCITY\"] = result[\"FG_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_ANGULAR_VELOCITY\"] = result[\"FG_ANGULAR_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_ACCELERATION\"] = result[\"FG_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_CENTRIPETAL_ACCELERATION\"] = result[\"FG_CENTRIPETAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_TANGENTIAL_ACCELERATION\"] = result[\"FG_TANGENTIAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "\n",
    "result[\"G_X\"] = result[\"G_X\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_Y\"] = result[\"G_Y\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_PRESSURE\"] = result[\"G_PRESSURE\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_AZIMUTH\"] = result[\"G_AZIMUTH\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_ELEVATION\"] = result[\"G_ELEVATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_POSITION\"] = result[\"G_POSITION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_DISPLACEMENT\"] = result[\"G_DISPLACEMENT\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_VELOCITY\"] = result[\"G_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_ANGULAR_VELOCITY\"] = result[\"G_ANGULAR_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_ACCELERATION\"] = result[\"G_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_CENTRIPETAL_ACCELERATION\"] = result[\"G_CENTRIPETAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_TANGENTIAL_ACCELERATION\"] = result[\"G_TANGENTIAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "\n",
    "\n",
    "result.loc[result[\"G_ID\"].str.contains(\"v\") & result[\"FG_ID\"].str.contains(\"v\"), \"F_G\"] = 1\n",
    "result.loc[result[\"G_ID\"].str.contains(\"v\") & result[\"FG_ID\"].str.contains(\"f\"), \"F_G\"] = 0\n",
    "\n",
    "result.to_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\final_test.csv\", index = False)\n",
    "\n",
    "\n",
    "print(\"complete test\")\n",
    "\n",
    "\n",
    "del genuine, gen_forg, dicti_g, dicti_fg, result, ids, new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca59d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3fb99e",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026488f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\train_gen.csv\")\n",
    "\n",
    "\n",
    "gen_forg = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\train_gen_forg.csv\")\n",
    "\n",
    "genuine = genuine.fillna(0)\n",
    "gen_forg = gen_forg.fillna(0)\n",
    "\n",
    "genuine = genuine.groupby('ID').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "gen_forg = gen_forg.groupby('ID').agg(lambda x: list(x)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abf6c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 14), (3000, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genuine.shape, gen_forg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c21dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "\n",
    "for i in gen_forg[\"ID\"]:\n",
    "    ids.append(i)\n",
    "    \n",
    "    \n",
    "new_id = []\n",
    "\n",
    "for i in ids:\n",
    "    \n",
    "    new_id.append(i)\n",
    "    \n",
    "gen_forg[\"ID\"] = new_id\n",
    "\n",
    "genuine['g_key'] = genuine['ID'].str[:4]\n",
    "gen_forg['fg_key'] = gen_forg['ID'].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fa6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ba591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f860a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca581f9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "genuine = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\train_gen.csv\")\n",
    "\n",
    "\n",
    "gen_forg = pd.read_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\train_gen_forg.csv\")\n",
    "\n",
    "genuine = genuine.fillna(0)\n",
    "gen_forg = gen_forg.fillna(0)\n",
    "\n",
    "genuine = genuine.groupby('ID').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "gen_forg = gen_forg.groupby('ID').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "\n",
    "ids = []\n",
    "\n",
    "for i in gen_forg[\"ID\"]:\n",
    "    ids.append(i)\n",
    "    \n",
    "    \n",
    "new_id = []\n",
    "\n",
    "for i in ids:\n",
    "    \n",
    "    new_id.append(i)\n",
    "    \n",
    "gen_forg[\"ID\"] = new_id\n",
    "\n",
    "genuine['g_key'] = genuine['ID'].str[:4]\n",
    "gen_forg['fg_key'] = gen_forg['ID'].str[:4]\n",
    "\n",
    "dicti_g = {\n",
    "    'ID':\"G_ID\", 'X':\"G_X\", 'Y':\"G_Y\", 'PRESSURE':\"G_PRESSURE\", 'AZIMUTH':\"G_AZIMUTH\", 'ELEVATION':\"G_ELEVATION\", \n",
    "    'POSITION':\"G_POSITION\",\n",
    "        'DISPLACEMENT':\"G_DISPLACEMENT\", 'VELOCITY':\"G_VELOCITY\", 'ANGULAR_VELOCITY':\"G_ANGULAR_VELOCITY\", 'ACCELERATION':\"G_ACCELERATION\",\n",
    "        'CENTRIPETAL_ACCELERATION':\"G_CENTRIPETAL_ACCELERATION\", 'TANGENTIAL_ACCELERATION':\"G_TANGENTIAL_ACCELERATION\"\n",
    "}\n",
    "\n",
    "genuine.rename(columns = dicti_g, inplace = True)\n",
    "\n",
    "dicti_fg = {\n",
    "    'ID':\"FG_ID\", 'X':\"FG_X\", 'Y':\"FG_Y\", 'PRESSURE':\"FG_PRESSURE\", 'AZIMUTH':\"FG_AZIMUTH\", 'ELEVATION':\"FG_ELEVATION\", \n",
    "    'POSITION':\"FG_POSITION\",\n",
    "        'DISPLACEMENT':\"FG_DISPLACEMENT\", 'VELOCITY':\"FG_VELOCITY\", 'ANGULAR_VELOCITY':\"FG_ANGULAR_VELOCITY\", 'ACCELERATION':\"FG_ACCELERATION\",\n",
    "        'CENTRIPETAL_ACCELERATION':\"FG_CENTRIPETAL_ACCELERATION\", 'TANGENTIAL_ACCELERATION':\"FG_TANGENTIAL_ACCELERATION\"\n",
    "}\n",
    "\n",
    "gen_forg.rename(columns = dicti_fg, inplace = True)\n",
    "\n",
    "genuine.rename(columns = {\"g_key\": \"key\"}, inplace = True)\n",
    "gen_forg.rename(columns = {\"fg_key\": \"key\"}, inplace = True)\n",
    "\n",
    "result = pd.merge(genuine, gen_forg, on ='key').drop(\"key\", 1)\n",
    "\n",
    "result[\"FG_X\"] = result[\"FG_X\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_Y\"] = result[\"FG_Y\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_PRESSURE\"] = result[\"FG_PRESSURE\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_AZIMUTH\"] = result[\"FG_AZIMUTH\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_ELEVATION\"] = result[\"FG_ELEVATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_POSITION\"] = result[\"FG_POSITION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_DISPLACEMENT\"] = result[\"FG_DISPLACEMENT\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_VELOCITY\"] = result[\"FG_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_ANGULAR_VELOCITY\"] = result[\"FG_ANGULAR_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_ACCELERATION\"] = result[\"FG_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_CENTRIPETAL_ACCELERATION\"] = result[\"FG_CENTRIPETAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"FG_TANGENTIAL_ACCELERATION\"] = result[\"FG_TANGENTIAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "\n",
    "result[\"G_X\"] = result[\"G_X\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_Y\"] = result[\"G_Y\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_PRESSURE\"] = result[\"G_PRESSURE\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_AZIMUTH\"] = result[\"G_AZIMUTH\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_ELEVATION\"] = result[\"G_ELEVATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_POSITION\"] = result[\"G_POSITION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_DISPLACEMENT\"] = result[\"G_DISPLACEMENT\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_VELOCITY\"] = result[\"G_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_ANGULAR_VELOCITY\"] = result[\"G_ANGULAR_VELOCITY\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_ACCELERATION\"] = result[\"G_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_CENTRIPETAL_ACCELERATION\"] = result[\"G_CENTRIPETAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "result[\"G_TANGENTIAL_ACCELERATION\"] = result[\"G_TANGENTIAL_ACCELERATION\"].apply(lambda a:round(np.mean(a), 3))\n",
    "\n",
    "\n",
    "result.loc[result[\"G_ID\"].str.contains(\"v\") & result[\"FG_ID\"].str.contains(\"v\"), \"F_G\"] = 1\n",
    "result.loc[result[\"G_ID\"].str.contains(\"v\") & result[\"FG_ID\"].str.contains(\"f\"), \"F_G\"] = 0\n",
    "\n",
    "\n",
    "result = result.drop([\"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "result.to_csv(r\"G:\\Signature Verification Project\\MCYT 100 Dataset\\Processed\\new_processed\\final_train.csv\", index = False)\n",
    "\n",
    "\n",
    "del genuine, gen_forg, dicti_g, dicti_fg, result, ids, new_id\n",
    "\n",
    "print(\"complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6c770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
